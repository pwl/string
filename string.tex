\documentclass[
a4paper,% paper dimensions
10pt,% font size
titlepage,% print title on a single page
%twocolumn,% text in two columns on a single page
twoside% two sided printing (page numbers on outer edge)
]{article}


% \pagestyle{myheadings}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amscd}
% \usepackage[polish]{babel}
% \usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{hyperref}
% \usepackage{graphicx}
% \usepackage{titlesec}
% \usepackage{afterpage}
% \usepackage[section]{placeins}


\begin{document}

\subsection{Recursive formulation}
We start with the equation
\begin{gather}
  \label{eq:wave0}
  (\rho+m\delta(x-L))\partial_{tt}\psi=\partial_{xx}\psi,
\end{gather}
which after the substitutions
\begin{gather}
  \label{eq:subs0}
  x\rightarrow x'=\frac{m}{\rho} x         \\
  t\rightarrow t'=\frac{m}{\sqrt{2\rho}} t \\
  L'=\frac{\rho L}{m}
\end{gather}
becomes
\begin{gather}
  \label{eq:wave0}
  (1+\delta(x-L))\partial_{tt}\psi=\frac{1}{2}\partial_{xx}\psi,
\end{gather}
with primes omitted, so the problem has one parameter (which can be
also shown using dimensional analysis). Futher, the most general
ansatz for the escaping wave to the right of the point mass is
\begin{gather}
  \label{eq:ansatz0}
  \psi(x,t)=
  \begin{cases}
    f(x-t)+g(x+t) & x\in[0,L] \\
    h(x-t)        & x\ge L,
  \end{cases}
\end{gather}
with conditions
\begin{gather}
  \label{eq:boundary}
  \psi(0,t) = 0\quad\text{zero at the boundary}\\
  \label{eq:continuity}
  \psi(L-,t)=\psi(L+,t)\quad\text{continuity}.
\end{gather}
which become
\begin{gather}
  \label{eq:ansatz0}
  \psi(x,t)=
  \begin{cases}
    -g(t-x)+g(x+t) & x\in[0,L] \\
    h(x-t)         & x\ge L.
  \end{cases}\\
  \label{eq:cont0}
  -g(t-L)+g(L+t)=h(L-t)\quad\text{continuity}
\end{gather}

Integrating \eqref{eq:wave0} we obtain
\begin{gather}
  \partial_{tt}\psi(L,t)=\frac{1}{2}(\partial_x\psi(L+,t)-\partial_x\psi(L-,t)).
\end{gather}
which glues together the solutions from different intervals along with
the continuity condition \eqref{eq:continuity}.

The preceding statements give rise to the following equation for $g$
\begin{equation}
  \begin{split}
    -g''(t-L)+g''(t+L)&=\frac{1}{2}(h'(L-t)-g'(t-L)-g'(t+L))\\
    &=\frac{1}{2}(g'(t-L)-g'(t+L)-g'(t-L)-g'(t+L))\\
    &=-g'(t+L),
  \end{split}
\end{equation}
and after the shift in $t$ and with $T:=2L$ we get
\begin{gather}
  g''(t+T)+g'(t+T)=g''(t)
\end{gather}
integration gives us
\begin{gather}
  g'(t+T)+g(t+T)=g'(t)+(g'(T)-g'(0)+g(T)).
\end{gather}
Adding a constant to $g$ does not change the equations, so we can
add such constant in order to cancel the $(g'(T)-g'(0)+g(T))$ term,
and we are then given the final form of equation for $g$
\begin{gather}
  \label{eq:dde}
  g'(t+T)+g(t+T)=g'(t),
\end{gather}
which is a kind of delayed differential equation, and for which one
can iteratively find a solution for arbitrary large times given the
function values in an interval $[a,a+T]$ where $a$ is an arbitrary
constant for convinience we shall fix $a=0$. Now we shall introduce a
family of functions $g_n\in\mathcal{C}([0,T])$ defined as
\begin{equation}
    g(t+nT)=g_n(t)\quad t\in[0,T]
\end{equation}
so the equation \eqref{eq:rec0} becomes
\begin{gather}
  \label{eq:rec0}
  \begin{split}
    &g'_{n+1}(t)+g_{n+1}(t)=g'_n(t),\\
    &g_{n+1}(0)=g_n(T)\quad\text{continuity condition}.\\
    &\text{with}\quad g_0(t)\quad\text{initial conditions}
  \end{split}
\end{gather}
The above equation can be solved by iteration
\begin{gather}\label{eq:defL}
  g_{n+1}(t)=(Lg_n)(t)=g_n(t)-e^{-t}\int_0^t e^s g_n(s)ds+e^{-t}(g_n(T)-g_n(0)).
\end{gather}
With $L:\mathcal{C}([0,T])\rightarrow \mathcal{C}([0,T])$. The
eigenvectors of $L$ are the soultions of the equation \eqref{eq:rec0}
with $g_{n+1}=\lambda g_n=\lambda g_\lambda$
\begin{gather}
  \lambda(g'_\lambda(t)+g_\lambda(t))=g'_\lambda(t),\\
  \lambda g_\lambda(0)=g_\lambda(T)\quad\text{quantization}.
\end{gather}
from which we obtain
\begin{gather}
  g_\lambda(t)=e^{\frac{\lambda}{\lambda+1}t},\\
  \lambda=e^{\frac{\lambda}{\lambda+1}T}\quad\text{quantization}.
\end{gather}
The last term in \eqref{eq:defL} may look suspicious due to its form
(explicit function times constant) but for eigenvectors it is simply
zeros altogether with lower boundary of integration according to the
quantization condition. The quantization for $\lambda$ gives rise to
the quasi-normal modes of equation \eqref{eq:wave0}.

\subsection{Quasinormal Modes - asymptotic expansion}
The transcendental equation for $\lambda$ can be written as
\begin{gather}\label{eq:qm0}
  \frac{\beta}{\beta+1}=e^{\beta T}
\end{gather}
where $\lambda=\frac{\beta}{\beta+1}$. We shall split $\beta$ into its
real and imaginary part: $\beta=i\Omega-\Gamma$.  Taking the absolute
value of \eqref{eq:qm0} we obtain the following equation
\begin{gather}\label{eq:qm1}
  \frac{\Omega^2+(\Gamma-1)^2}{\Omega^2+\Gamma^2}=e^{2\Gamma T}
\end{gather}
Let's assume $\Gamma<0$, then from the equality
\begin{gather}\label{eq:g_ineq}
  e^{2\Gamma T}-1=\frac{1-2\Gamma}{\Omega^2+\Gamma^2}
\end{gather}
contradiction appears and so we deduce $\Gamma>0$, which in turn leads
to the fact that $\Gamma<\frac{1}{2}$. From the fact $\Gamma>0$ one
can conclude that $L$ is bounded, and thus continous on the space spanned
by its eigenvectors because
\begin{gather}
|\lambda|^2=e^{-2\Gamma T}<1.
\end{gather}
Equation
\eqref{eq:qm1} can be solved for $\Omega^2$
\begin{gather}
  \begin{split}
    \Omega^2&=\frac{1-2\Gamma-\Gamma^2(e^{2\Gamma T}-1)}{e^{2\Gamma T}-1}\\
    &=\frac{1}{2\Gamma T}-\frac{2+T}{2T}+\Gamma\frac{6+T}{6}+\mathcal{O}(\Gamma^2),\\
    \Omega&=\pm(\frac{1}{\sqrt{2T}}\frac{1}{\sqrt{\Gamma}}-\frac{2+T}{2\sqrt{2T}}\sqrt{\Gamma}+\mathcal{O}(\Gamma^{3/2}))
  \end{split}
\end{gather}
We shall introduce a new parameter
$\eta:=\frac{\sqrt{T}}{2\sqrt{\pi\Gamma}}$ obtaining the
parametrization $\beta(\eta)$ (the reason for such peculiar
parametrization will become clear later.

\begin{align}\label{eq:qmparam}
  \Gamma&=\frac{T}{2\pi^2\eta^2},\\
  \Omega&=\pm(\frac{\pi}{T}\eta-2(2+T)\pi\frac{1}{\eta}+\mathcal{O}(\eta^{-3}),\\
  % \pm\sqrt{\frac{\eta^4-2\eta^2-(e^{2T/\eta^2}-1)}{\eta^4(e^{2T/\eta^2}-1)}}=\\
  % \pm(\frac{1}{\sqrt{2 T}}\eta-\frac{2+T}{2\sqrt{2T}}\frac{1}{\eta}+\mathcal{O}(\eta^{-3})),\\
  \beta&=\pm i(\frac{\pi}{T}\eta-2(2+T)\pi\frac{1}{\eta})-\frac{T}{2\pi^2\eta^2}+\mathcal{O}(\eta^{-3})
\end{align}

Second equation for $\Omega$ and $\Gamma$ is given by
\begin{equation}
  \label{eq:second_og}
  \Omega\cot{\Omega T}=\Gamma(\Gamma-1)+\Omega^2
\end{equation}
the above equation can be solved for real $\Gamma$ when
\begin{equation}
  \label{eq:second_og_delta}
  \Delta=1-4\Omega(\Omega-\cot(\Omega T))\ge 0
\end{equation}
or equivalently for $\Omega\gg 1$
\begin{equation}
  \cot(\Omega T)\ge\Omega
\end{equation}

It can be easily seen (by assuming $\Omega T=n\pi+\epsilon_n$,
$\epsilon_n\ll 1$) that \eqref{eq:second_og_delta} is fulfilled when
$\Omega\in[n\pi/T,n\pi/T+\epsilon_n/T]$, where
$\epsilon_n=(\sqrt{n^2\pi^2+4T}-n\pi)/2\rightarrow T/n\pi$, hence
$\Omega\rightarrow n\pi/T+\mathcal{O}(1/n)$. Substituting $\Omega
T=n\pi+\epsilon$ to \eqref{eq:second_og_delta} we get
\begin{align}
  \label{eq:second_og_delta_e}
  \Delta&=4\frac{n\pi}{T}\big(\frac{1}{\epsilon}-\frac{n\pi}{T}),\\
  \Gamma_\pm&=\frac{1}{2}(1\pm\sqrt{\Delta}).
\end{align}
Up to this point we assumed $\Omega>0$, but the same reasoning can be
used for $\Omega<0$ giving the same asymptotic relation (which is also
a consequence of the fact, that if $\beta$ fulfills the
\eqref{eq:second_og} then also $\bar\beta$ does). Now the meaning of
the parametrization in \eqref{eq:qmparam} becomes clear, $\beta(\eta)$
should be the solution of the \eqref{eq:second_og} for
$\eta\in\mathbb{Z}$.

% TODO: Proof of the sentence above!
% TODO: Plots of both equations!
% TODO: Relations for Omega ~ 0

Substituting $\Omega=0$ to the \eqref{eq:second_og} we get
\begin{equation}
  \label{eq:omega0}
  \frac{\Gamma}{\Gamma-1}=e^{-\Gamma T},
\end{equation}
which has no solution for real $\Gamma$, and so there is no real
eigenvalue for $L$.
% TODO: Plot of T(Gamma)


\subsection{Iterations of $L$}

We should now calculate $g(t)=(L^n h_0)(t-nT)$ for
\begin{gather}
  h_0(t)=\sum_\lambda a_\lambda g_\lambda(t).
\end{gather}
We have
\begin{gather}
  (L^n h_0)(t)=\sum_\lambda \lambda^n a_\lambda g_\lambda(t).
\end{gather}
Utilizing quantization condition for $\lambda$ we obtain
\begin{align}\label{eq:series}
  (L^n h_0)(t) =&\sum_\lambda a_\lambda e^{\frac{\lambda}{\lambda+1}(t+nT)}=\\
  &\sum_\beta a_{\lambda(\beta)}e^{\beta(t+nT)}
  \end{align}
Inserting the \eqref{eq:qmparam} to \eqref{eq:series} yields
\begin{gather}\label{eq:nthfold}
  \begin{split}
    (L^n h_0)(t-nT) &=\sum_\eta a_{\lambda(\eta)} e^{\beta(\eta)t}\\
    &\approx \int_{\eta_0}^\infty a_{\lambda(\eta)}\exp((ib\eta-\frac{ic}{\eta}-\frac{1}{\eta^2})t)d\eta+c.c.
  \end{split}
\end{gather}
The remaining problem is the asymptotic form of $a_{\lambda}$ for
reasonable initial data (which cannot be simply computed using scalar
product, because eigenvectors are not orthogonal in their current
form) and integration of the above integral to get energy leak in time
(see \eqref{eq:enleak}). The integration should be doable using the
method of steepest descent or some other method for highly oscillatory
integrands assuming $t\gg 1$. After this the asymptotic expansion in
time should be easily obtained, and so the energy leak.

% We are looking for $(L^ng_0)$ for $n\rightarrow\infty$.

% From \eqref{eq:g_ineq} we know that $\Gamma<1/2$ and so
% \begin{align}
%   \Gamma&=\frac{1}{2}(1-\sqrt{\Delta})\\
%   \Delta=(1-2\Gamma)^2
% \end{align}

% equation
% \begin{gather}\label{eq:beta}
%   \frac{\beta}{\beta+1}=e^{\beta T}
% \end{gather}
% defines the discrete set $A=\{\beta_i\}$ with elements $\beta_i$ being
% solutions to \eqref{eq:beta}. It is easy to notice that if $\beta_i$
% is in $A$ then $\bar{\beta_i}$ also is in $A$. From now on we shall
% utilize this symmetry by writting $\beta_{-i}=\bar{\beta_i}$. As in
% the previous paragraph we will name the real and imaginary part of
% $\beta_i$ the $-\Gamma_i$ and $\Omega_i$ respectively.



\subsection{Energy}
The energy of the whole string is given by the functional
\begin{align}
  \begin{split}
    E(\psi)&=\frac{1}{2}\int_0^\infty dx (2(1+\delta(x-L))\psi_t^2+\psi_x^2)\\
    &=\frac{1}{2}\int_0^L dx(2\psi_t^2+\psi_x^2)+\frac{1}{2}\int_L^\infty dx(2\psi_t^2+\psi_x^2)+\psi_t^2\bigg|_{x=L}\\
    &=E_{in}(\psi)+E_{esc}(\psi)
  \end{split}
\end{align}
with
\begin{align}
  &E_{in}(\psi)=\frac{1}{2}\int_0^L dx(2\psi_t^2+\psi_x^2)+\psi_t^2\bigg|_{x=L}\\
  &E_{esc}(\psi)=\frac{1}{2}\int_L^\infty dx(2\psi_t^2+\psi_x^2)
\end{align}.

The energy is conserved, thus
\begin{align}
  \partial_t E_{in}(\psi)=-\partial_t E_{out}(\psi),
\end{align}
so it is enough to calculate only outgoing energy
\begin{align}
  \partial_t E_{in}(\psi)=&-\partial_t E_{out}(\psi)=-\int_L^\infty dx(\partial_x(\psi_t\psi_x))\\
  =&\psi_x\psi_t\big|_{x=L+}\\
  =&-h'(L-t)^2=-(g'(t-L)-g'(t+L))^2=-g(t+L)^2.
\end{align}
After the cosmetic shift in time we get
\begin{align}
  \partial_t E_{in}(\psi)\approx -g(t)^2
\end{align}

% \begin{gather}
%   \begin{split}\label{eq:enleak}
%     \partial_t E_{in}(\psi)&=\int_0^L(\partial_x(\psi_t\psi_x))+\psi_{tt}\psi_t\bigg|_{x=L}=\\
%     &=(\psi_x+\psi_{tt})\psi_t\bigg|_{x=L}=\\
%     &=(g'(t-L)+g'(t+L)-g''(t-L)+g''(t+L))(g'(t+L)-g'(t-L))\\
%     &=(g'(t-L)+g'(t+L)-g'(t+L))(g'(t+L)-g'(t-L))\\
%     &=-g'(t-L)g(t+L)\\
%     &=-(g'(t+L)+g(t+L))g(t+L)\\
%     &=-\frac{1}{2}\partial_tg(t+L)^2-g(t+L)^2
%   \end{split}
% \end{gather}
% So the highest order dependency on $t$ will be the $g(t+L)^2$ term (assuming $g\sim t^{-\alpha}$), so
% we can write that for large times we have
% \begin{gather}
%   \partial_t E_{in}(\psi)\sim~-g^2(t+L)<0
% \end{gather}

% Substituting
% \begin{gather}
%   g_n(t)=\frac{1}{\sqrt{2\pi}}\int_{\mathbb{R}}\hat{g_n}(\omega)e^{i\omega t}d\omega
% \end{gather}
% one gets
% \begin{gather}
%   g_{n+1}(t)=\frac{1}{\sqrt{2\pi}}\int_{\mathbb{R}}\hat{g_n}(\omega)\bigg[
%   \frac{i\omega}{1+i\omega}e^{i\omega t}+
%   e^{i\omega T-t}-
%   \frac{i\omega}{1+i\omega}e^{-(i\omega+1)t}
%   \bigg]d\omega.
% \end{gather}
% by multiplying by $e^{-i\omega't}/\sqrt{2\pi}$ and integrating
% $\int_0^{T}dt$ (this assumes that $g_n$ is zero everywhere except the
% interval $[a,a+T]$ where we have chosen $a$ to be $0$) one obtains
% \begin{gather}
%   \hat{g_{n+1}}(\omega')=\hat{g_n}(\omega')\frac{i\omega'}{1+i\omega'}+
%   \frac{1}{2\pi}\int_{\mathbb{R}}\hat{g_n}(\omega)\frac{e^{i\omega T}-e^{-T-iT(\omega'-\omega)}}{1+i\omega'}
% \end{gather}

\section{Notes}

\subsection{Scalar product}

Scalar product is the standard scalar product for
$L^2([0,T])$. Orthogonal Fourier basis is given by
\begin{equation}
  \label{eq:fourier_base}
  \phi_n(x)=e^{i x n \pi/T}=e^{\omega_n x}
\end{equation}
as well as the eigenfunctions of $L$.
\begin{equation}
  g_n(x)=e^{ \beta_n x}
\end{equation}
The following quantities can be calculated
\begin{equation}
  (e^{\beta x},e^{\omega x})=
  \begin{cases}
    T & \bar\beta+\omega=0 \\
    \frac{1}{\bar{\beta}+\omega}\big(e^{(\bar\beta+\omega)t}-1\big)         & \bar\beta+\omega\ne0
  \end{cases}
\end{equation}

\subsection{Asymptotic form of energy}


The energy can be approximated as follows. First we define
\begin{align}
  I(t):=\int_a^\infty e^{a(x,t)}e^{itx}dx.
\end{align}
The above function can be expanded to finite series by repetitively
applying integration by parts
\begin{align}
  I(t)&=e^{ita}\sum_{n=0}^N\frac{d^n}{dx^n}\bigg|_{x=a}e^{a(x,t)} \left(\frac{i}{t}\right)^{n+1}+\epsilon_{N+1}(t),\\
  \epsilon_{N}(t)&=\left(\frac{i}{t}\right)^{N}\int_a^\infty \frac{d^{N}}{dx^{N}}\bigg|_{x=a}e^{a(x,t)}e^{itx}dx
\end{align}
N can be set to infinity if $\epsilon_N=O(x^{-N-1})$, which is true if
$\frac{d^{N}}{dx^{N}}\bigg|_{x=a}e^{a(x,t)}=O(x^{-1-\delta})$ for
$\delta>0$. If this is true we can write
\begin{align}
  I(t)=e^{ita}\sum_{n=0}^\infty\frac{d^n}{dx^n}\bigg|_{x=a}e^{a(x,t)} \left(\frac{i}{t}\right)^{n+1}.
\end{align}
From now on we assume $\partial_x a(x,t)>>1$. Using the identity for
$n$-th derivative of function composition
\begin{align}
  \frac{d^n}{dx^n}\bigg|_{x=x_0}e^{f(x)}=B_n(f'(x_0),...,f^{(n)}(x_0))e^{f(x)}
\end{align}
and the asymptotic form of Bell polynomials
\begin{align}
  B_n(x_1,...,x_n) = x_1^n + O(x_i^{n-1})
\end{align}
we can further simplify the formula for $I(t)$
\begin{align}
  I(t)&=e^{ita}e^{a(a,t)}\frac{i}{t}\sum_{n=0}^\infty \left(\frac{ia'(a,t)}{t}\right)^{n}\\
  &=e^{ita}e^{a(a,t)}\frac{i}{t-ia'(a,t)}.
\end{align}

In the case of \eqref{eq:nthfold} after suitable change of variables we get
\begin{align}
  \log(|g(t)|^2)\sim A-Bt-2\log t.
\end{align}
where $A$ is depends of initial value of $g(t)$, but $B$ does not (at
least for large times).

\end{document}
